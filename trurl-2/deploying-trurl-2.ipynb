{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fd2fa6e",
   "metadata": {},
   "source": [
    "# TRURL 2 on Amazon SageMaker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318937da",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5da55cf-430f-49fa-b07f-862f491f5162",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "\n",
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "from sagemaker.huggingface import HuggingFaceModel, get_huggingface_llm_image_uri\n",
    "\n",
    "# Reducing verbosity of the `sagemaker` library.\n",
    "\n",
    "sagemaker_config_logger = logging.getLogger('sagemaker.config')\n",
    "sagemaker_logger = logging.getLogger('sagemaker')\n",
    "\n",
    "sagemaker_config_logger.setLevel(logging.ERROR)\n",
    "sagemaker_logger.setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e6da63-2ca8-4924-a791-338be42a855c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "\tiam = boto3.client('iam')\n",
    "\trole = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "print(f'Amazon SageMaker IAM Role ARN: {role}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19938bb2-ea8a-410a-961e-6ecfbf8fa8de",
   "metadata": {},
   "source": [
    "## Deploying model into Amazon SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ddd1cf-d3d2-49e6-b7b2-761b6f761e1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = 'trurl-2-7b'\n",
    "\n",
    "instance_type = 'ml.g5.2xlarge'\n",
    "num_of_gpus = 1\n",
    "\n",
    "container_startup_timeout = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a808b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "env = {\n",
    "    'HF_MODEL_ID': f'Voicelab/{model_name}',\n",
    "    'SM_NUM_GPUS': json.dumps(num_of_gpus)\n",
    "}\n",
    "\n",
    "hf_image_uri = get_huggingface_llm_image_uri('huggingface', version='1.1.0')\n",
    "\n",
    "huggingface_model = HuggingFaceModel(\n",
    "\timage_uri=hf_image_uri,\n",
    "\tenv=env,\n",
    "\trole=role, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebec762",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor = huggingface_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=instance_type,\n",
    "    container_startup_health_check_timeout=container_startup_timeout,\n",
    "    endpoint_name='example-trurl2-endpoint'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11dfa13a-b2e0-4cf5-921d-38ee9c02697f",
   "metadata": {},
   "source": [
    "## Let's test the freshly deployed endpoint!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5980541",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = {\n",
    "    'inputs': '<s>[INST]Kim jest Stanisław Lem?[/INST]',\n",
    "    'parameters': {\n",
    "        'do_sample': True,\n",
    "        'top_p': 0.6,\n",
    "        'temperature': 0.9,\n",
    "        'top_k': 50,\n",
    "        'max_new_tokens': 100,\n",
    "        'repetition_penalty': 1.05,\n",
    "        'stop': ['</s>']\n",
    "    }\n",
    "}\n",
    "\n",
    "predictor.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7e31dc-1c65-4079-9df2-763ea6a4ba19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = {\n",
    "    'inputs': '<s>[INST]Czym zajmuje się firma VoiceLab?[/INST]',\n",
    "    'parameters': {\n",
    "        'do_sample': True,\n",
    "        'top_p': 0.6,\n",
    "        'temperature': 0.9,\n",
    "        'top_k': 50,\n",
    "        'max_new_tokens': 100,\n",
    "        'repetition_penalty': 1.05,\n",
    "        'stop': ['</s>']\n",
    "    }\n",
    "}\n",
    "\n",
    "predictor.predict(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a84f024-754f-443e-9e0f-e74b089846d9",
   "metadata": {},
   "source": [
    "## Okay, it's time for something more complicated!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f0bf5c-8b3a-4cdf-b2ba-bc5fbf0d1ed2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install mediawikiapi==1.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784df594-b55a-47eb-b8ad-3ea2c5e6246f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from mediawikiapi import MediaWikiAPI\n",
    "\n",
    "mediawikiapi = MediaWikiAPI()\n",
    "mediawikiapi.config.language = 'pl'\n",
    "\n",
    "pl_nobel_prizes_page = mediawikiapi.page('Lista_laureatów_Nagrody_Nobla_związanych_z_Polską')\n",
    "pl_nobel_prizes_df = pd.read_html(pl_nobel_prizes_page.url, attrs={'class': 'wikitable'})[0]\n",
    "pl_nobel_prizes = pl_nobel_prizes_df.drop([0, 1, 4, 5], axis=1).drop([0], axis=0).to_string(index=False, header=False)\n",
    "\n",
    "print(pl_nobel_prizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63eebfb3-e543-4e19-99b3-ea2b95dcea83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = f\"\"\"<s>[INST] \n",
    "<<SYS>> \n",
    "Na podstawie przygotowanego kontekstu odpowiedz na zadane pytanie. Jeśli nie ma tej informacji w kontekście, nie dodawaj niczego. Jeśli nie znasz odpowiedzi, nie odpowiadaj. Odpowiadaj jak najbardziej zwięźle.\n",
    "<</SYS>> \n",
    "Tabela z danymi Polek i Polaków którzy otrzymali nagrody Nobla: \n",
    "\n",
    "{pl_nobel_prizes} \n",
    "\n",
    "Jako pierwsze słowo w pierwszej kolumnie mamy imię, potem nazwisko, oraz w nawiasach rok urodzenia oraz śmierci. Załóż, że polskie kobiece imiona kończą się na literę a. W drugiej kolumnie mamy kategorię przyznanej nagrody Nobla. Jeśli dana osoba otrzymała więcej niż jedną nagrodę, w tej kolumnie jest więcej niż jedno słowo. Dodatkowo, w takim przypadku przy każdej kategorii w nawiasie jest rok przynania nagrody.\n",
    "\n",
    "Podaj sumaryczną liczbę nagród Nobla które przynano polskim kobietom.\n",
    "[/INST]\n",
    "\"\"\"\n",
    "\n",
    "data = {\n",
    "    'inputs': prompt,\n",
    "    'parameters': {\n",
    "        'do_sample': True,\n",
    "        'top_p': 0.6,\n",
    "        'temperature': 0.9,\n",
    "        'top_k': 50,\n",
    "        'max_new_tokens': 50,\n",
    "        'repetition_penalty': 1.05,\n",
    "        'stop': ['</s>']\n",
    "    }\n",
    "}\n",
    "\n",
    "response = predictor.predict(data)\n",
    "text = response[0]['generated_text']\n",
    "print(text[len(prompt):])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18bffbc7-e82f-4d05-acf8-2f40c000da00",
   "metadata": {},
   "source": [
    "## Let's make it conversational!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709da581-ecd4-4000-834a-285ad0686666",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"<s>[INST]\n",
    "<<SYS>> \n",
    "Jesteś pomocnym asystentem. Będziemy grać w grę o nazwie '20 pytań'. Twoim zadaniem jest odgadnąć co mam na myśli, zadając po jednym pytaniu na które mogę odpowiedzie tylko 'tak' lub 'nie'. Gra dobiegnie końca gdy wyczerpie się limit 20 pytań, lub odgadniesz konkretną rzecz wcześniej.\n",
    "<</SYS>> \n",
    "Jestem gotów, zadaj pierwsze pytanie.\n",
    "[/INST]\n",
    "\"\"\"\n",
    "\n",
    "data = {\n",
    "    'inputs': prompt,\n",
    "    'parameters': {\n",
    "        'do_sample': True,\n",
    "        'top_p': 0.6,\n",
    "        'temperature': 0.9,\n",
    "        'top_k': 50,\n",
    "        'max_new_tokens': 512,\n",
    "        'repetition_penalty': 1.05,\n",
    "        'stop': ['</s>']\n",
    "    }\n",
    "}\n",
    "\n",
    "response = predictor.predict(data)\n",
    "text = response[0]['generated_text']\n",
    "print(text[len(prompt):])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972ab8f3-ddb3-48f9-b14a-adaf0fe2527d",
   "metadata": {},
   "source": [
    "## Enough exploration - it's time to clean-up and develop something!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fa53a7-1abc-40ba-9068-023049b99c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e783b10-de98-4c39-a402-a7af5add9a04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "interpreter": {
   "hash": "c281c456f1b8161c8906f4af2c08ed2c40c50136979eaae69688b01f70e9f4a9"
  },
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-west-1:470317259841:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
